{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Houses Kaggle Competition (revisited with Deep Learning üî•) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src='https://wagon-public-datasets.s3.amazonaws.com/data-science-images/ML/kaggle-batch-challenge.png' width=600>](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "‚öôÔ∏è Let's re-use our previous **pipeline** built in the module **`05-07-Ensemble-Methods`** and try to improve our final predictions with a Neural Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) Libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 16:14:47.876075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:14:48.143094: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-20 16:14:48.155579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-20 16:14:48.155609: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-20 16:14:48.216785: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-20 16:14:49.503359: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-20 16:14:49.503586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-20 16:14:49.503599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# DATA MANIPULATION\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "# DATA VISUALISATION\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# VIEWING OPTIONS IN THE NOTEBOOK\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) üöÄ Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Let's load our **training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv\")\n",
    "X = data.drop(columns='SalePrice')\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  \n",
       "0       WD        Normal  \n",
       "1       WD        Normal  \n",
       "2       WD        Normal  \n",
       "3       WD       Abnorml  \n",
       "4       WD        Normal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 80), (1460,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Let's also load the **test set**\n",
    "\n",
    "‚ùóÔ∏è Remember ‚ùóÔ∏è You have access to `X_test` but only Kaggle has `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Train/Val Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Holdout** ‚ùì \n",
    "\n",
    "As you are not allowed to use the test set (and you don't have access to `y_test` anyway), split your dataset into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Import the preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ You will find in `utils/preprocessor.py` the **`data-preprocessing pipeline`** that was built in our previous iteration.\n",
    "\n",
    "‚ùì Run the cell below, and make sure you understand what the pipeline does. Look at the code in `preprocessor.py` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtFullBath&#x27;,\n",
       "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                                   &#x27;EnclosedPorch&#x27;,\n",
       "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
       "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
       "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;MiscFeature&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
       "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
       "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                                   &#x27;Utilities&#x27;])])),\n",
       "                (&#x27;selectpercentile&#x27;,\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x7f8582345480&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtFullBath&#x27;,\n",
       "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                                   &#x27;EnclosedPorch&#x27;,\n",
       "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
       "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
       "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;MiscFeature&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
       "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
       "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                                   &#x27;Utilities&#x27;])])),\n",
       "                (&#x27;selectpercentile&#x27;,\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x7f8582345480&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;knnimputer&#x27;, KNNImputer()),\n",
       "                                                 (&#x27;minmaxscaler&#x27;,\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;,\n",
       "                                  &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                  &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                  &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                  &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;,\n",
       "                                  &#x27;GrLivArea&#x27;, &#x27;HalfBath...\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;,\n",
       "                                  &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                  &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;,\n",
       "                                  &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                  &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;,\n",
       "                                  &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
       "                                  &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                  &#x27;Utilities&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;, &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;, &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;, &#x27;GrLivArea&#x27;, &#x27;HalfBath&#x27;, &#x27;Id&#x27;, &#x27;KitchenAbvGr&#x27;, &#x27;LotArea&#x27;, &#x27;LotFrontage&#x27;, &#x27;LowQualFinSF&#x27;, &#x27;MSSubClass&#x27;, &#x27;MasVnrArea&#x27;, &#x27;MiscVal&#x27;, &#x27;MoSold&#x27;, &#x27;OpenPorchSF&#x27;, &#x27;OverallCond&#x27;, &#x27;OverallQual&#x27;, &#x27;PoolArea&#x27;, &#x27;ScreenPorch&#x27;, &#x27;TotRmsAbvGrd&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;WoodDeckSF&#x27;, &#x27;YearBuilt&#x27;, &#x27;YearRemodAdd&#x27;, &#x27;YrSold&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;, &#x27;BsmtFinType2&#x27;, &#x27;BsmtQual&#x27;, &#x27;Electrical&#x27;, &#x27;ExterCond&#x27;, &#x27;ExterQual&#x27;, &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;, &#x27;Functional&#x27;, &#x27;GarageCond&#x27;, &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;HeatingQC&#x27;, &#x27;KitchenQual&#x27;, &#x27;LandContour&#x27;, &#x27;LandSlope&#x27;, &#x27;LotShape&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[[&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;No&#x27;, &#x27;Mn&#x27;, &#x27;Av&#x27;, &#x27;Gd&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
       "                            &#x27;GLQ&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
       "                            &#x27;GLQ&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Mix&#x27;, &#x27;FuseP&#x27;, &#x27;FuseF&#x27;, &#x27;FuseA&#x27;,\n",
       "                            &#x27;SBrkr&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;...\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;RFn&#x27;, &#x27;Fin&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Low&#x27;, &#x27;Bnk&#x27;, &#x27;HLS&#x27;, &#x27;Lvl&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Sev&#x27;, &#x27;Mod&#x27;, &#x27;Gtl&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;IR3&#x27;, &#x27;IR2&#x27;, &#x27;IR1&#x27;, &#x27;Reg&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;N&#x27;, &#x27;P&#x27;, &#x27;Y&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;]],\n",
       "               handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nominal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;, &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;, &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;, &#x27;Utilities&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=75,\n",
       "                 score_func=&lt;function mutual_info_regression at 0x7f8582345480&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_encoder',\n",
       "                                                  Pipeline(steps=[('knnimputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['1stFlrSF', '2ndFlrSF',\n",
       "                                                   '3SsnPorch', 'BedroomAbvGr',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtFullBath',\n",
       "                                                   'BsmtHalfBath', 'BsmtUnfSF',\n",
       "                                                   'EnclosedPorch',\n",
       "                                                   'Fireplaces', 'FullBath',\n",
       "                                                   'GarageArea', 'GarageCars...\n",
       "                                                   'CentralAir', 'Condition1',\n",
       "                                                   'Condition2', 'Exterior1st',\n",
       "                                                   'Exterior2nd', 'Foundation',\n",
       "                                                   'GarageType', 'Heating',\n",
       "                                                   'HouseStyle', 'LotConfig',\n",
       "                                                   'MSZoning', 'MasVnrType',\n",
       "                                                   'MiscFeature',\n",
       "                                                   'Neighborhood', 'RoofMatl',\n",
       "                                                   'RoofStyle', 'SaleCondition',\n",
       "                                                   'SaleType', 'Street',\n",
       "                                                   'Utilities'])])),\n",
       "                ('selectpercentile',\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=<function mutual_info_regression at 0x7f8582345480>))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.preprocessor import create_preproc\n",
    "\n",
    "preproc = create_preproc(X_train)\n",
    "preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Scaling your numerical features and encoding the categorical features** ‚ùì\n",
    "\n",
    "Apply these transformations to _both_ your training set and your validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtFullBath&#x27;,\n",
       "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                                   &#x27;EnclosedPorch&#x27;,\n",
       "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
       "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
       "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;MiscFeature&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
       "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
       "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                                   &#x27;Utilities&#x27;])])),\n",
       "                (&#x27;selectpercentile&#x27;,\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x7f8582345480&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtFullBath&#x27;,\n",
       "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                                   &#x27;EnclosedPorch&#x27;,\n",
       "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
       "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
       "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;MiscFeature&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
       "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
       "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                                   &#x27;Utilities&#x27;])])),\n",
       "                (&#x27;selectpercentile&#x27;,\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x7f8582345480&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;knnimputer&#x27;, KNNImputer()),\n",
       "                                                 (&#x27;minmaxscaler&#x27;,\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;,\n",
       "                                  &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                  &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                  &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                  &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;,\n",
       "                                  &#x27;GrLivArea&#x27;, &#x27;HalfBath...\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;,\n",
       "                                  &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                  &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;,\n",
       "                                  &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                  &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;,\n",
       "                                  &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
       "                                  &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                  &#x27;Utilities&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;, &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;, &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;, &#x27;GrLivArea&#x27;, &#x27;HalfBath&#x27;, &#x27;Id&#x27;, &#x27;KitchenAbvGr&#x27;, &#x27;LotArea&#x27;, &#x27;LotFrontage&#x27;, &#x27;LowQualFinSF&#x27;, &#x27;MSSubClass&#x27;, &#x27;MasVnrArea&#x27;, &#x27;MiscVal&#x27;, &#x27;MoSold&#x27;, &#x27;OpenPorchSF&#x27;, &#x27;OverallCond&#x27;, &#x27;OverallQual&#x27;, &#x27;PoolArea&#x27;, &#x27;ScreenPorch&#x27;, &#x27;TotRmsAbvGrd&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;WoodDeckSF&#x27;, &#x27;YearBuilt&#x27;, &#x27;YearRemodAdd&#x27;, &#x27;YrSold&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;, &#x27;BsmtFinType2&#x27;, &#x27;BsmtQual&#x27;, &#x27;Electrical&#x27;, &#x27;ExterCond&#x27;, &#x27;ExterQual&#x27;, &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;, &#x27;Functional&#x27;, &#x27;GarageCond&#x27;, &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;HeatingQC&#x27;, &#x27;KitchenQual&#x27;, &#x27;LandContour&#x27;, &#x27;LandSlope&#x27;, &#x27;LotShape&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[[&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;No&#x27;, &#x27;Mn&#x27;, &#x27;Av&#x27;, &#x27;Gd&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
       "                            &#x27;GLQ&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
       "                            &#x27;GLQ&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Mix&#x27;, &#x27;FuseP&#x27;, &#x27;FuseF&#x27;, &#x27;FuseA&#x27;,\n",
       "                            &#x27;SBrkr&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;...\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;RFn&#x27;, &#x27;Fin&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Low&#x27;, &#x27;Bnk&#x27;, &#x27;HLS&#x27;, &#x27;Lvl&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Sev&#x27;, &#x27;Mod&#x27;, &#x27;Gtl&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;IR3&#x27;, &#x27;IR2&#x27;, &#x27;IR1&#x27;, &#x27;Reg&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;N&#x27;, &#x27;P&#x27;, &#x27;Y&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;]],\n",
       "               handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nominal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;, &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;, &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;, &#x27;Utilities&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=75,\n",
       "                 score_func=&lt;function mutual_info_regression at 0x7f8582345480&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_encoder',\n",
       "                                                  Pipeline(steps=[('knnimputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['1stFlrSF', '2ndFlrSF',\n",
       "                                                   '3SsnPorch', 'BedroomAbvGr',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtFullBath',\n",
       "                                                   'BsmtHalfBath', 'BsmtUnfSF',\n",
       "                                                   'EnclosedPorch',\n",
       "                                                   'Fireplaces', 'FullBath',\n",
       "                                                   'GarageArea', 'GarageCars...\n",
       "                                                   'CentralAir', 'Condition1',\n",
       "                                                   'Condition2', 'Exterior1st',\n",
       "                                                   'Exterior2nd', 'Foundation',\n",
       "                                                   'GarageType', 'Heating',\n",
       "                                                   'HouseStyle', 'LotConfig',\n",
       "                                                   'MSZoning', 'MasVnrType',\n",
       "                                                   'MiscFeature',\n",
       "                                                   'Neighborhood', 'RoofMatl',\n",
       "                                                   'RoofStyle', 'SaleCondition',\n",
       "                                                   'SaleType', 'Street',\n",
       "                                                   'Utilities'])])),\n",
       "                ('selectpercentile',\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=<function mutual_info_regression at 0x7f8582345480>))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc.transform(X_train)\n",
    "X_val = preproc.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) üîÆ Your predictions in Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ This is your first **regression** task with Keras! \n",
    "\n",
    "üí° Here a few tips to get started:\n",
    "- Kaggle's [rule](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) requires to minimize **`rmsle`** (Root Mean Square Log Error). \n",
    "    - As you can see, we can specify `msle` directly as a loss-function with Tensorflow.Keras!\n",
    "    - Just remember to take the square-root of your loss results to read your rmsle metric.\n",
    "    \n",
    "    \n",
    "üòÉ The best boosted-tree ***rmsle*** score to beat is around ***0.13***\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://i.pinimg.com/564x/4c/fe/ef/4cfeef34af09973211f584e8307b433c.jpg\" alt=\"`Impossible mission\" style=\"height: 300px; width:500px;\"/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "‚ùì **Your mission, should you choose to accept it:** ‚ùì\n",
    "- üí™ Beat the best boosted-tree üí™ \n",
    "\n",
    "    - Your responsibilities are:\n",
    "        - to build the ***best neural network architecture*** possible,\n",
    "        - and to control the number of epochs to ***avoid overfitting***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Predicting the houses' prices using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Preliminary Question: Initializing a Neural Network** ‚ùì\n",
    "\n",
    "Create a function `initialize_model` which initializes a Dense Neural network:\n",
    "- You are responsible for designing the architecture (number of layers, number of neurons)\n",
    "- The function should also compile the model with the following parameters:\n",
    "    - ***optimizer = \"adam\"***\n",
    "    - ***loss = \"msle\"*** (_Optimizing directly for the Squared Log Error!_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 157)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    ############################# \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(5, activation=\"relu\", input_dim = 157))\n",
    "    model.add(layers.Dense(4, activation=\"relu\"))\n",
    "    model.add(layers.Dense(3, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"linear\"))\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss='msle', \n",
    "                  optimizer='adam',\n",
    "                 metrics=\"msle\") \n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions/Guidance** ‚ùì\n",
    "\n",
    "1. Initialize a Neural Network\n",
    "2. Train it\n",
    "3. Evaluate its performance\n",
    "4. Is the model overfitting the dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 138.0361 - msle: 138.0361 - val_loss: 125.1318 - val_msle: 125.1318\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 115.5289 - msle: 115.5289 - val_loss: 108.0186 - val_msle: 108.0186\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 103.6898 - msle: 103.6898 - val_loss: 99.3110 - val_msle: 99.3110\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 95.7603 - msle: 95.7603 - val_loss: 91.9528 - val_msle: 91.9528\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 89.1983 - msle: 89.1983 - val_loss: 86.2564 - val_msle: 86.2564\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 84.0946 - msle: 84.0946 - val_loss: 81.6771 - val_msle: 81.6771\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 79.8740 - msle: 79.8740 - val_loss: 77.7947 - val_msle: 77.7947\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 76.2366 - msle: 76.2366 - val_loss: 74.3962 - val_msle: 74.3962\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 73.0209 - msle: 73.0209 - val_loss: 71.3582 - val_msle: 71.3582\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 70.1270 - msle: 70.1270 - val_loss: 68.6098 - val_msle: 68.6098\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 67.4936 - msle: 67.4936 - val_loss: 66.0933 - val_msle: 66.0933\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 65.0730 - msle: 65.0730 - val_loss: 63.7721 - val_msle: 63.7721\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 62.8331 - msle: 62.8331 - val_loss: 61.6160 - val_msle: 61.6160\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 60.7476 - msle: 60.7476 - val_loss: 59.6045 - val_msle: 59.6045\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 58.7970 - msle: 58.7970 - val_loss: 57.7199 - val_msle: 57.7199\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 56.9660 - msle: 56.9660 - val_loss: 55.9459 - val_msle: 55.9459\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 55.2406 - msle: 55.2406 - val_loss: 54.2725 - val_msle: 54.2725\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 53.6106 - msle: 53.6106 - val_loss: 52.6904 - val_msle: 52.6904\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 52.0677 - msle: 52.0677 - val_loss: 51.1891 - val_msle: 51.1891\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 50.6023 - msle: 50.6023 - val_loss: 49.7646 - val_msle: 49.7646\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 49.2103 - msle: 49.2103 - val_loss: 48.4073 - val_msle: 48.4073\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 47.8836 - msle: 47.8836 - val_loss: 47.1149 - val_msle: 47.1149\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 46.6185 - msle: 46.6185 - val_loss: 45.8808 - val_msle: 45.8808\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 45.4101 - msle: 45.4101 - val_loss: 44.7015 - val_msle: 44.7015\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 44.2548 - msle: 44.2548 - val_loss: 43.5714 - val_msle: 43.5714\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 43.1474 - msle: 43.1474 - val_loss: 42.4908 - val_msle: 42.4908\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 42.0868 - msle: 42.0868 - val_loss: 41.4533 - val_msle: 41.4533\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 41.0690 - msle: 41.0690 - val_loss: 40.4566 - val_msle: 40.4566\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 40.0903 - msle: 40.0903 - val_loss: 39.5006 - val_msle: 39.5006\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 39.1505 - msle: 39.1505 - val_loss: 38.5794 - val_msle: 38.5794\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 38.2455 - msle: 38.2455 - val_loss: 37.6926 - val_msle: 37.6926\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 37.3740 - msle: 37.3740 - val_loss: 36.8380 - val_msle: 36.8380\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 36.5338 - msle: 36.5338 - val_loss: 36.0141 - val_msle: 36.0141\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 35.7232 - msle: 35.7232 - val_loss: 35.2194 - val_msle: 35.2194\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 34.9405 - msle: 34.9405 - val_loss: 34.4524 - val_msle: 34.4524\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 34.1849 - msle: 34.1849 - val_loss: 33.7102 - val_msle: 33.7102\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 33.4540 - msle: 33.4540 - val_loss: 32.9925 - val_msle: 32.9925\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 32.7471 - msle: 32.7471 - val_loss: 32.2979 - val_msle: 32.2979\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 32.0626 - msle: 32.0626 - val_loss: 31.6259 - val_msle: 31.6259\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 31.3998 - msle: 31.3998 - val_loss: 30.9745 - val_msle: 30.9745\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 30.7574 - msle: 30.7574 - val_loss: 30.3429 - val_msle: 30.3429\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 30.1346 - msle: 30.1346 - val_loss: 29.7301 - val_msle: 29.7301\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 29.5300 - msle: 29.5300 - val_loss: 29.1360 - val_msle: 29.1360\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 28.9434 - msle: 28.9434 - val_loss: 28.5590 - val_msle: 28.5590\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 28.3736 - msle: 28.3736 - val_loss: 27.9983 - val_msle: 27.9983\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 27.8201 - msle: 27.8201 - val_loss: 27.4530 - val_msle: 27.4530\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 27.2815 - msle: 27.2815 - val_loss: 26.9237 - val_msle: 26.9237\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 26.7582 - msle: 26.7582 - val_loss: 26.4082 - val_msle: 26.4082\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 26.2490 - msle: 26.2490 - val_loss: 25.9062 - val_msle: 25.9062\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 25.7530 - msle: 25.7530 - val_loss: 25.4179 - val_msle: 25.4179\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 25.2702 - msle: 25.2702 - val_loss: 24.9422 - val_msle: 24.9422\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 24.7998 - msle: 24.7998 - val_loss: 24.4790 - val_msle: 24.4790\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 24.3416 - msle: 24.3416 - val_loss: 24.0267 - val_msle: 24.0267\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 23.8944 - msle: 23.8944 - val_loss: 23.5865 - val_msle: 23.5865\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 23.4586 - msle: 23.4586 - val_loss: 23.1567 - val_msle: 23.1567\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 23.0333 - msle: 23.0333 - val_loss: 22.7374 - val_msle: 22.7374\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 22.6184 - msle: 22.6184 - val_loss: 22.3276 - val_msle: 22.3276\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 22.2128 - msle: 22.2128 - val_loss: 21.9285 - val_msle: 21.9285\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 21.8174 - msle: 21.8174 - val_loss: 21.5377 - val_msle: 21.5377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 21.4307 - msle: 21.4307 - val_loss: 21.1563 - val_msle: 21.1563\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 21.0530 - msle: 21.0530 - val_loss: 20.7835 - val_msle: 20.7835\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 20.6838 - msle: 20.6838 - val_loss: 20.4191 - val_msle: 20.4191\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 20.3228 - msle: 20.3228 - val_loss: 20.0627 - val_msle: 20.0627\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 19.9696 - msle: 19.9696 - val_loss: 19.7145 - val_msle: 19.7145\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 19.6245 - msle: 19.6245 - val_loss: 19.3731 - val_msle: 19.3731\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 19.2864 - msle: 19.2864 - val_loss: 19.0392 - val_msle: 19.0392\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 18.9556 - msle: 18.9556 - val_loss: 18.7128 - val_msle: 18.7128\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 18.6318 - msle: 18.6318 - val_loss: 18.3931 - val_msle: 18.3931\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 18.3148 - msle: 18.3148 - val_loss: 18.0798 - val_msle: 18.0798\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 18.0041 - msle: 18.0041 - val_loss: 17.7732 - val_msle: 17.7732\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 17.7000 - msle: 17.7000 - val_loss: 17.4724 - val_msle: 17.4724\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 17.4018 - msle: 17.4018 - val_loss: 17.1779 - val_msle: 17.1779\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 17.1097 - msle: 17.1097 - val_loss: 16.8891 - val_msle: 16.8891\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 16.8232 - msle: 16.8232 - val_loss: 16.6066 - val_msle: 16.6066\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 16.5426 - msle: 16.5426 - val_loss: 16.3290 - val_msle: 16.3290\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 16.2673 - msle: 16.2673 - val_loss: 16.0566 - val_msle: 16.0566\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 15.9972 - msle: 15.9972 - val_loss: 15.7897 - val_msle: 15.7897\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 15.7322 - msle: 15.7322 - val_loss: 15.5281 - val_msle: 15.5281\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 15.4724 - msle: 15.4724 - val_loss: 15.2709 - val_msle: 15.2709\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 15.2172 - msle: 15.2172 - val_loss: 15.0190 - val_msle: 15.0190\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 14.9669 - msle: 14.9669 - val_loss: 14.7713 - val_msle: 14.7713\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 14.7212 - msle: 14.7212 - val_loss: 14.5282 - val_msle: 14.5282\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 14.4799 - msle: 14.4799 - val_loss: 14.2897 - val_msle: 14.2897\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 14.2428 - msle: 14.2428 - val_loss: 14.0558 - val_msle: 14.0558\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 14.0105 - msle: 14.0105 - val_loss: 13.8253 - val_msle: 13.8253\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 13.7818 - msle: 13.7818 - val_loss: 13.5993 - val_msle: 13.5993\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 13.5573 - msle: 13.5573 - val_loss: 13.3774 - val_msle: 13.3774\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 13.3369 - msle: 13.3369 - val_loss: 13.1590 - val_msle: 13.1590\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 13.1200 - msle: 13.1200 - val_loss: 12.9449 - val_msle: 12.9449\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 12.9072 - msle: 12.9072 - val_loss: 12.7341 - val_msle: 12.7341\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 12.6977 - msle: 12.6977 - val_loss: 12.5274 - val_msle: 12.5274\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 12.4921 - msle: 12.4921 - val_loss: 12.3236 - val_msle: 12.3236\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 12.2899 - msle: 12.2899 - val_loss: 12.1233 - val_msle: 12.1233\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 12.0909 - msle: 12.0909 - val_loss: 11.9268 - val_msle: 11.9268\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 11.8955 - msle: 11.8955 - val_loss: 11.7333 - val_msle: 11.7333\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 11.7032 - msle: 11.7032 - val_loss: 11.5428 - val_msle: 11.5428\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 11.5140 - msle: 11.5140 - val_loss: 11.3558 - val_msle: 11.3558\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 11.3279 - msle: 11.3279 - val_loss: 11.1721 - val_msle: 11.1721\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 11.1452 - msle: 11.1452 - val_loss: 10.9906 - val_msle: 10.9906\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 10.9650 - msle: 10.9650 - val_loss: 10.8126 - val_msle: 10.8126\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 10.7880 - msle: 10.7880 - val_loss: 10.6374 - val_msle: 10.6374\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 10.6137 - msle: 10.6137 - val_loss: 10.4651 - val_msle: 10.4651\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 10.4423 - msle: 10.4423 - val_loss: 10.2954 - val_msle: 10.2954\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 10.2736 - msle: 10.2736 - val_loss: 10.1284 - val_msle: 10.1284\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 10.1076 - msle: 10.1076 - val_loss: 9.9638 - val_msle: 9.9638\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 9.9441 - msle: 9.9441 - val_loss: 9.8021 - val_msle: 9.8021\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 9.7832 - msle: 9.7832 - val_loss: 9.6428 - val_msle: 9.6428\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 9.6248 - msle: 9.6248 - val_loss: 9.4861 - val_msle: 9.4861\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 9.4690 - msle: 9.4690 - val_loss: 9.3317 - val_msle: 9.3317\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 9.3154 - msle: 9.3154 - val_loss: 9.1799 - val_msle: 9.1799\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 9.1643 - msle: 9.1643 - val_loss: 9.0303 - val_msle: 9.0303\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 9.0155 - msle: 9.0155 - val_loss: 8.8831 - val_msle: 8.8831\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 8.8690 - msle: 8.8690 - val_loss: 8.7380 - val_msle: 8.7380\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 8.7247 - msle: 8.7247 - val_loss: 8.5952 - val_msle: 8.5952\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 8.5826 - msle: 8.5826 - val_loss: 8.4546 - val_msle: 8.4546\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 8.4426 - msle: 8.4426 - val_loss: 8.3161 - val_msle: 8.3161\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 8.3048 - msle: 8.3048 - val_loss: 8.1797 - val_msle: 8.1797\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 8.1691 - msle: 8.1691 - val_loss: 8.0452 - val_msle: 8.0452\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 11ms/step - loss: 8.0353 - msle: 8.0353 - val_loss: 7.9131 - val_msle: 7.9131\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 7.9037 - msle: 7.9037 - val_loss: 7.7825 - val_msle: 7.7825\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 7.7739 - msle: 7.7739 - val_loss: 7.6540 - val_msle: 7.6540\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 7.6461 - msle: 7.6461 - val_loss: 7.5273 - val_msle: 7.5273\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 7.5200 - msle: 7.5200 - val_loss: 7.4029 - val_msle: 7.4029\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 7.3960 - msle: 7.3960 - val_loss: 7.2801 - val_msle: 7.2801\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 7.2738 - msle: 7.2738 - val_loss: 7.1590 - val_msle: 7.1590\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 7.1534 - msle: 7.1534 - val_loss: 7.0397 - val_msle: 7.0397\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 7.0347 - msle: 7.0347 - val_loss: 6.9224 - val_msle: 6.9224\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 6.9178 - msle: 6.9178 - val_loss: 6.8068 - val_msle: 6.8068\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 6.8027 - msle: 6.8027 - val_loss: 6.6926 - val_msle: 6.6926\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 6.6891 - msle: 6.6891 - val_loss: 6.5803 - val_msle: 6.5803\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 6.5772 - msle: 6.5772 - val_loss: 6.4697 - val_msle: 6.4697\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 6.4671 - msle: 6.4671 - val_loss: 6.3604 - val_msle: 6.3604\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 6.3584 - msle: 6.3584 - val_loss: 6.2531 - val_msle: 6.2531\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 6.2514 - msle: 6.2514 - val_loss: 6.1473 - val_msle: 6.1473\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 6.1459 - msle: 6.1459 - val_loss: 6.0430 - val_msle: 6.0430\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 6.0421 - msle: 6.0421 - val_loss: 5.9399 - val_msle: 5.9399\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 5.9395 - msle: 5.9395 - val_loss: 5.8387 - val_msle: 5.8387\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 5.8387 - msle: 5.8387 - val_loss: 5.7386 - val_msle: 5.7386\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 5.7392 - msle: 5.7392 - val_loss: 5.6400 - val_msle: 5.6400\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 5.6411 - msle: 5.6411 - val_loss: 5.5432 - val_msle: 5.5432\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 5.5445 - msle: 5.5445 - val_loss: 5.4476 - val_msle: 5.4476\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 5.4493 - msle: 5.4493 - val_loss: 5.3534 - val_msle: 5.3534\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 5.3555 - msle: 5.3555 - val_loss: 5.2604 - val_msle: 5.2604\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 5.2630 - msle: 5.2630 - val_loss: 5.1689 - val_msle: 5.1689\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 5.1718 - msle: 5.1718 - val_loss: 5.0789 - val_msle: 5.0789\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 5.0821 - msle: 5.0821 - val_loss: 4.9899 - val_msle: 4.9899\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 4.9935 - msle: 4.9935 - val_loss: 4.9024 - val_msle: 4.9024\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 4.9063 - msle: 4.9063 - val_loss: 4.8160 - val_msle: 4.8160\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.8203 - msle: 4.8203 - val_loss: 4.7311 - val_msle: 4.7311\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 4.7357 - msle: 4.7357 - val_loss: 4.6472 - val_msle: 4.6472\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 4.6522 - msle: 4.6522 - val_loss: 4.5646 - val_msle: 4.5646\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.5699 - msle: 4.5699 - val_loss: 4.4833 - val_msle: 4.4833\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 4.4888 - msle: 4.4888 - val_loss: 4.4030 - val_msle: 4.4030\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 4.4089 - msle: 4.4089 - val_loss: 4.3241 - val_msle: 4.3241\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.3302 - msle: 4.3302 - val_loss: 4.2462 - val_msle: 4.2462\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.2526 - msle: 4.2526 - val_loss: 4.1693 - val_msle: 4.1693\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.1761 - msle: 4.1761 - val_loss: 4.0938 - val_msle: 4.0938\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.1008 - msle: 4.1008 - val_loss: 4.0194 - val_msle: 4.0194\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.0266 - msle: 4.0266 - val_loss: 3.9460 - val_msle: 3.9460\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.9535 - msle: 3.9535 - val_loss: 3.8735 - val_msle: 3.8735\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.8814 - msle: 3.8814 - val_loss: 3.8023 - val_msle: 3.8023\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.8104 - msle: 3.8104 - val_loss: 3.7321 - val_msle: 3.7321\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.7404 - msle: 3.7404 - val_loss: 3.6630 - val_msle: 3.6630\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.6716 - msle: 3.6716 - val_loss: 3.5947 - val_msle: 3.5947\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.6036 - msle: 3.6036 - val_loss: 3.5276 - val_msle: 3.5276\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.5367 - msle: 3.5367 - val_loss: 3.4616 - val_msle: 3.4616\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.4709 - msle: 3.4709 - val_loss: 3.3964 - val_msle: 3.3964\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.4060 - msle: 3.4060 - val_loss: 3.3322 - val_msle: 3.3322\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.3420 - msle: 3.3420 - val_loss: 3.2690 - val_msle: 3.2690\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.2790 - msle: 3.2790 - val_loss: 3.2068 - val_msle: 3.2068\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.2171 - msle: 3.2171 - val_loss: 3.1452 - val_msle: 3.1452\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.1558 - msle: 3.1558 - val_loss: 3.0852 - val_msle: 3.0852\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.0958 - msle: 3.0958 - val_loss: 3.0256 - val_msle: 3.0256\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.0365 - msle: 3.0365 - val_loss: 2.9670 - val_msle: 2.9670\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.9781 - msle: 2.9781 - val_loss: 2.9093 - val_msle: 2.9093\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.9206 - msle: 2.9206 - val_loss: 2.8526 - val_msle: 2.8526\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.8640 - msle: 2.8640 - val_loss: 2.7967 - val_msle: 2.7967\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.8083 - msle: 2.8083 - val_loss: 2.7416 - val_msle: 2.7416\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 11ms/step - loss: 2.7534 - msle: 2.7534 - val_loss: 2.6873 - val_msle: 2.6873\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.6993 - msle: 2.6993 - val_loss: 2.6341 - val_msle: 2.6341\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.6462 - msle: 2.6462 - val_loss: 2.5813 - val_msle: 2.5813\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.5937 - msle: 2.5937 - val_loss: 2.5297 - val_msle: 2.5297\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.5422 - msle: 2.5422 - val_loss: 2.4787 - val_msle: 2.4787\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4913 - msle: 2.4913 - val_loss: 2.4287 - val_msle: 2.4287\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.4414 - msle: 2.4414 - val_loss: 2.3792 - val_msle: 2.3792\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3922 - msle: 2.3922 - val_loss: 2.3304 - val_msle: 2.3304\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3436 - msle: 2.3436 - val_loss: 2.2828 - val_msle: 2.2828\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2960 - msle: 2.2960 - val_loss: 2.2357 - val_msle: 2.2357\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2490 - msle: 2.2490 - val_loss: 2.1894 - val_msle: 2.1894\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2028 - msle: 2.2028 - val_loss: 2.1437 - val_msle: 2.1437\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1573 - msle: 2.1573 - val_loss: 2.0988 - val_msle: 2.0988\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1124 - msle: 2.1124 - val_loss: 2.0546 - val_msle: 2.0546\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0684 - msle: 2.0684 - val_loss: 2.0111 - val_msle: 2.0111\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 2.0249 - msle: 2.0249 - val_loss: 1.9682 - val_msle: 1.9682\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9822 - msle: 1.9822 - val_loss: 1.9260 - val_msle: 1.9260\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9402 - msle: 1.9402 - val_loss: 1.8844 - val_msle: 1.8844\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8987 - msle: 1.8987 - val_loss: 1.8437 - val_msle: 1.8437\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.8580 - msle: 1.8580 - val_loss: 1.8033 - val_msle: 1.8033\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.8178 - msle: 1.8178 - val_loss: 1.7637 - val_msle: 1.7637\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.7783 - msle: 1.7783 - val_loss: 1.7246 - val_msle: 1.7246\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.7393 - msle: 1.7393 - val_loss: 1.6865 - val_msle: 1.6865\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7011 - msle: 1.7011 - val_loss: 1.6486 - val_msle: 1.6486\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6634 - msle: 1.6634 - val_loss: 1.6113 - val_msle: 1.6113\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6263 - msle: 1.6263 - val_loss: 1.5747 - val_msle: 1.5747\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5897 - msle: 1.5897 - val_loss: 1.5388 - val_msle: 1.5388\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5538 - msle: 1.5538 - val_loss: 1.5033 - val_msle: 1.5033\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5184 - msle: 1.5184 - val_loss: 1.4681 - val_msle: 1.4681\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4835 - msle: 1.4835 - val_loss: 1.4338 - val_msle: 1.4338\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.4491 - msle: 1.4491 - val_loss: 1.4000 - val_msle: 1.4000\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.4153 - msle: 1.4153 - val_loss: 1.3667 - val_msle: 1.3667\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3821 - msle: 1.3821 - val_loss: 1.3340 - val_msle: 1.3340\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.3494 - msle: 1.3494 - val_loss: 1.3017 - val_msle: 1.3017\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.3172 - msle: 1.3172 - val_loss: 1.2698 - val_msle: 1.2698\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.2854 - msle: 1.2854 - val_loss: 1.2388 - val_msle: 1.2388\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.2542 - msle: 1.2542 - val_loss: 1.2081 - val_msle: 1.2081\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.2236 - msle: 1.2236 - val_loss: 1.1777 - val_msle: 1.1777\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 1.1933 - msle: 1.1933 - val_loss: 1.1479 - val_msle: 1.1479\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.1636 - msle: 1.1636 - val_loss: 1.1186 - val_msle: 1.1186\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.1343 - msle: 1.1343 - val_loss: 1.0900 - val_msle: 1.0900\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 1.1056 - msle: 1.1056 - val_loss: 1.0617 - val_msle: 1.0617\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.0774 - msle: 1.0774 - val_loss: 1.0337 - val_msle: 1.0337\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 1.0495 - msle: 1.0495 - val_loss: 1.0064 - val_msle: 1.0064\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.0222 - msle: 1.0222 - val_loss: 0.9796 - val_msle: 0.9796\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.9954 - msle: 0.9954 - val_loss: 0.9532 - val_msle: 0.9532\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.9690 - msle: 0.9690 - val_loss: 0.9271 - val_msle: 0.9271\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.9431 - msle: 0.9431 - val_loss: 0.9017 - val_msle: 0.9017\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.9176 - msle: 0.9176 - val_loss: 0.8768 - val_msle: 0.8768\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8927 - msle: 0.8927 - val_loss: 0.8521 - val_msle: 0.8521\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8681 - msle: 0.8681 - val_loss: 0.8280 - val_msle: 0.8280\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.8441 - msle: 0.8441 - val_loss: 0.8045 - val_msle: 0.8045\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.8205 - msle: 0.8205 - val_loss: 0.7813 - val_msle: 0.7813\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.7974 - msle: 0.7974 - val_loss: 0.7585 - val_msle: 0.7585\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.7747 - msle: 0.7747 - val_loss: 0.7364 - val_msle: 0.7364\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.7525 - msle: 0.7525 - val_loss: 0.7146 - val_msle: 0.7146\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.7308 - msle: 0.7308 - val_loss: 0.6933 - val_msle: 0.6933\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.7096 - msle: 0.7096 - val_loss: 0.6723 - val_msle: 0.6723\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6887 - msle: 0.6887 - val_loss: 0.6520 - val_msle: 0.6520\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6683 - msle: 0.6683 - val_loss: 0.6320 - val_msle: 0.6320\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6484 - msle: 0.6484 - val_loss: 0.6126 - val_msle: 0.6126\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6290 - msle: 0.6290 - val_loss: 0.5935 - val_msle: 0.5935\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6099 - msle: 0.6099 - val_loss: 0.5750 - val_msle: 0.5750\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5914 - msle: 0.5914 - val_loss: 0.5569 - val_msle: 0.5569\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5733 - msle: 0.5733 - val_loss: 0.5392 - val_msle: 0.5392\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5557 - msle: 0.5557 - val_loss: 0.5219 - val_msle: 0.5219\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5384 - msle: 0.5384 - val_loss: 0.5051 - val_msle: 0.5051\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5217 - msle: 0.5217 - val_loss: 0.4888 - val_msle: 0.4888\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.5054 - msle: 0.5054 - val_loss: 0.4728 - val_msle: 0.4728\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4895 - msle: 0.4895 - val_loss: 0.4574 - val_msle: 0.4574\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4741 - msle: 0.4741 - val_loss: 0.4422 - val_msle: 0.4422\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4590 - msle: 0.4590 - val_loss: 0.4278 - val_msle: 0.4278\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4445 - msle: 0.4445 - val_loss: 0.4137 - val_msle: 0.4137\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4304 - msle: 0.4304 - val_loss: 0.3997 - val_msle: 0.3997\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4166 - msle: 0.4166 - val_loss: 0.3864 - val_msle: 0.3864\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4033 - msle: 0.4033 - val_loss: 0.3734 - val_msle: 0.3734\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3903 - msle: 0.3903 - val_loss: 0.3609 - val_msle: 0.3609\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3778 - msle: 0.3778 - val_loss: 0.3488 - val_msle: 0.3488\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3657 - msle: 0.3657 - val_loss: 0.3371 - val_msle: 0.3371\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3540 - msle: 0.3540 - val_loss: 0.3256 - val_msle: 0.3256\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3426 - msle: 0.3426 - val_loss: 0.3146 - val_msle: 0.3146\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3316 - msle: 0.3316 - val_loss: 0.3041 - val_msle: 0.3041\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3211 - msle: 0.3211 - val_loss: 0.2936 - val_msle: 0.2936\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3108 - msle: 0.3108 - val_loss: 0.2839 - val_msle: 0.2839\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3010 - msle: 0.3010 - val_loss: 0.2743 - val_msle: 0.2743\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2914 - msle: 0.2914 - val_loss: 0.2651 - val_msle: 0.2651\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2822 - msle: 0.2822 - val_loss: 0.2563 - val_msle: 0.2563\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2734 - msle: 0.2734 - val_loss: 0.2478 - val_msle: 0.2478\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.2649 - msle: 0.2649 - val_loss: 0.2396 - val_msle: 0.2396\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2567 - msle: 0.2567 - val_loss: 0.2317 - val_msle: 0.2317\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2488 - msle: 0.2488 - val_loss: 0.2242 - val_msle: 0.2242\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2412 - msle: 0.2412 - val_loss: 0.2168 - val_msle: 0.2168\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2339 - msle: 0.2339 - val_loss: 0.2098 - val_msle: 0.2098\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2270 - msle: 0.2270 - val_loss: 0.2031 - val_msle: 0.2031\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2203 - msle: 0.2203 - val_loss: 0.1967 - val_msle: 0.1967\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2138 - msle: 0.2138 - val_loss: 0.1906 - val_msle: 0.1906\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2077 - msle: 0.2077 - val_loss: 0.1847 - val_msle: 0.1847\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2017 - msle: 0.2017 - val_loss: 0.1791 - val_msle: 0.1791\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1961 - msle: 0.1961 - val_loss: 0.1737 - val_msle: 0.1737\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1907 - msle: 0.1907 - val_loss: 0.1685 - val_msle: 0.1685\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1856 - msle: 0.1856 - val_loss: 0.1635 - val_msle: 0.1635\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1806 - msle: 0.1806 - val_loss: 0.1589 - val_msle: 0.1589\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1759 - msle: 0.1759 - val_loss: 0.1545 - val_msle: 0.1545\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1715 - msle: 0.1715 - val_loss: 0.1501 - val_msle: 0.1501\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1672 - msle: 0.1672 - val_loss: 0.1462 - val_msle: 0.1462\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1631 - msle: 0.1631 - val_loss: 0.1422 - val_msle: 0.1422\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1592 - msle: 0.1592 - val_loss: 0.1386 - val_msle: 0.1386\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1555 - msle: 0.1555 - val_loss: 0.1351 - val_msle: 0.1351\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1520 - msle: 0.1520 - val_loss: 0.1317 - val_msle: 0.1317\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1487 - msle: 0.1487 - val_loss: 0.1287 - val_msle: 0.1287\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1455 - msle: 0.1455 - val_loss: 0.1256 - val_msle: 0.1256\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1425 - msle: 0.1425 - val_loss: 0.1228 - val_msle: 0.1228\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1396 - msle: 0.1396 - val_loss: 0.1202 - val_msle: 0.1202\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1370 - msle: 0.1370 - val_loss: 0.1176 - val_msle: 0.1176\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1343 - msle: 0.1343 - val_loss: 0.1153 - val_msle: 0.1153\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1320 - msle: 0.1320 - val_loss: 0.1129 - val_msle: 0.1129\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1296 - msle: 0.1296 - val_loss: 0.1108 - val_msle: 0.1108\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1275 - msle: 0.1275 - val_loss: 0.1088 - val_msle: 0.1088\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1254 - msle: 0.1254 - val_loss: 0.1069 - val_msle: 0.1069\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1235 - msle: 0.1235 - val_loss: 0.1051 - val_msle: 0.1051\n",
      "Epoch 299/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1217 - msle: 0.1217 - val_loss: 0.1034 - val_msle: 0.1034\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1199 - msle: 0.1199 - val_loss: 0.1019 - val_msle: 0.1019\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1183 - msle: 0.1183 - val_loss: 0.1004 - val_msle: 0.1004\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1168 - msle: 0.1168 - val_loss: 0.0989 - val_msle: 0.0989\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1153 - msle: 0.1153 - val_loss: 0.0976 - val_msle: 0.0976\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1139 - msle: 0.1139 - val_loss: 0.0963 - val_msle: 0.0963\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1127 - msle: 0.1127 - val_loss: 0.0952 - val_msle: 0.0952\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1115 - msle: 0.1115 - val_loss: 0.0941 - val_msle: 0.0941\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1103 - msle: 0.1103 - val_loss: 0.0931 - val_msle: 0.0931\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1093 - msle: 0.1093 - val_loss: 0.0921 - val_msle: 0.0921\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1082 - msle: 0.1082 - val_loss: 0.0912 - val_msle: 0.0912\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1073 - msle: 0.1073 - val_loss: 0.0904 - val_msle: 0.0904\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1064 - msle: 0.1064 - val_loss: 0.0896 - val_msle: 0.0896\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1056 - msle: 0.1056 - val_loss: 0.0888 - val_msle: 0.0888\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1048 - msle: 0.1048 - val_loss: 0.0881 - val_msle: 0.0881\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1040 - msle: 0.1040 - val_loss: 0.0874 - val_msle: 0.0874\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1033 - msle: 0.1033 - val_loss: 0.0868 - val_msle: 0.0868\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1027 - msle: 0.1027 - val_loss: 0.0862 - val_msle: 0.0862\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1020 - msle: 0.1020 - val_loss: 0.0857 - val_msle: 0.0857\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1015 - msle: 0.1015 - val_loss: 0.0852 - val_msle: 0.0852\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1009 - msle: 0.1009 - val_loss: 0.0847 - val_msle: 0.0847\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1004 - msle: 0.1004 - val_loss: 0.0842 - val_msle: 0.0842\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0999 - msle: 0.0999 - val_loss: 0.0838 - val_msle: 0.0838\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0994 - msle: 0.0994 - val_loss: 0.0834 - val_msle: 0.0834\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0989 - msle: 0.0989 - val_loss: 0.0830 - val_msle: 0.0830\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0985 - msle: 0.0985 - val_loss: 0.0826 - val_msle: 0.0826\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0981 - msle: 0.0981 - val_loss: 0.0822 - val_msle: 0.0822\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0977 - msle: 0.0977 - val_loss: 0.0819 - val_msle: 0.0819\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0973 - msle: 0.0973 - val_loss: 0.0816 - val_msle: 0.0816\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0969 - msle: 0.0969 - val_loss: 0.0813 - val_msle: 0.0813\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0966 - msle: 0.0966 - val_loss: 0.0810 - val_msle: 0.0810\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0963 - msle: 0.0963 - val_loss: 0.0807 - val_msle: 0.0807\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0959 - msle: 0.0959 - val_loss: 0.0804 - val_msle: 0.0804\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0956 - msle: 0.0956 - val_loss: 0.0801 - val_msle: 0.0801\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0953 - msle: 0.0953 - val_loss: 0.0798 - val_msle: 0.0798\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0950 - msle: 0.0950 - val_loss: 0.0796 - val_msle: 0.0796\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0947 - msle: 0.0947 - val_loss: 0.0793 - val_msle: 0.0793\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0944 - msle: 0.0944 - val_loss: 0.0791 - val_msle: 0.0791\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0941 - msle: 0.0941 - val_loss: 0.0788 - val_msle: 0.0788\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0938 - msle: 0.0938 - val_loss: 0.0786 - val_msle: 0.0786\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0935 - msle: 0.0935 - val_loss: 0.0784 - val_msle: 0.0784\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0933 - msle: 0.0933 - val_loss: 0.0781 - val_msle: 0.0781\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0930 - msle: 0.0930 - val_loss: 0.0779 - val_msle: 0.0779\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0927 - msle: 0.0927 - val_loss: 0.0776 - val_msle: 0.0776\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0924 - msle: 0.0924 - val_loss: 0.0774 - val_msle: 0.0774\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0922 - msle: 0.0922 - val_loss: 0.0772 - val_msle: 0.0772\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0919 - msle: 0.0919 - val_loss: 0.0769 - val_msle: 0.0769\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0916 - msle: 0.0916 - val_loss: 0.0767 - val_msle: 0.0767\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0914 - msle: 0.0914 - val_loss: 0.0764 - val_msle: 0.0764\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0911 - msle: 0.0911 - val_loss: 0.0762 - val_msle: 0.0762\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0908 - msle: 0.0908 - val_loss: 0.0760 - val_msle: 0.0760\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0906 - msle: 0.0906 - val_loss: 0.0757 - val_msle: 0.0757\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0903 - msle: 0.0903 - val_loss: 0.0755 - val_msle: 0.0755\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0900 - msle: 0.0900 - val_loss: 0.0752 - val_msle: 0.0752\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0897 - msle: 0.0897 - val_loss: 0.0750 - val_msle: 0.0750\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0894 - msle: 0.0894 - val_loss: 0.0747 - val_msle: 0.0747\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0892 - msle: 0.0892 - val_loss: 0.0745 - val_msle: 0.0745\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0889 - msle: 0.0889 - val_loss: 0.0742 - val_msle: 0.0742\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0886 - msle: 0.0886 - val_loss: 0.0740 - val_msle: 0.0740\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0883 - msle: 0.0883 - val_loss: 0.0737 - val_msle: 0.0737\n",
      "Epoch 359/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0880 - msle: 0.0880 - val_loss: 0.0735 - val_msle: 0.0735\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0877 - msle: 0.0877 - val_loss: 0.0732 - val_msle: 0.0732\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0875 - msle: 0.0875 - val_loss: 0.0730 - val_msle: 0.0730\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0872 - msle: 0.0872 - val_loss: 0.0727 - val_msle: 0.0727\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0869 - msle: 0.0869 - val_loss: 0.0724 - val_msle: 0.0724\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0866 - msle: 0.0866 - val_loss: 0.0722 - val_msle: 0.0722\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0863 - msle: 0.0863 - val_loss: 0.0719 - val_msle: 0.0719\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0860 - msle: 0.0860 - val_loss: 0.0716 - val_msle: 0.0716\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0856 - msle: 0.0856 - val_loss: 0.0713 - val_msle: 0.0713\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0853 - msle: 0.0853 - val_loss: 0.0711 - val_msle: 0.0711\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0850 - msle: 0.0850 - val_loss: 0.0708 - val_msle: 0.0708\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0847 - msle: 0.0847 - val_loss: 0.0705 - val_msle: 0.0705\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0844 - msle: 0.0844 - val_loss: 0.0702 - val_msle: 0.0702\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0841 - msle: 0.0841 - val_loss: 0.0700 - val_msle: 0.0700\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0838 - msle: 0.0838 - val_loss: 0.0697 - val_msle: 0.0697\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0834 - msle: 0.0834 - val_loss: 0.0694 - val_msle: 0.0694\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0831 - msle: 0.0831 - val_loss: 0.0691 - val_msle: 0.0691\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0828 - msle: 0.0828 - val_loss: 0.0688 - val_msle: 0.0688\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0825 - msle: 0.0825 - val_loss: 0.0685 - val_msle: 0.0685\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0821 - msle: 0.0821 - val_loss: 0.0682 - val_msle: 0.0682\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0818 - msle: 0.0818 - val_loss: 0.0679 - val_msle: 0.0679\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0815 - msle: 0.0815 - val_loss: 0.0676 - val_msle: 0.0676\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0811 - msle: 0.0811 - val_loss: 0.0673 - val_msle: 0.0673\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0808 - msle: 0.0808 - val_loss: 0.0670 - val_msle: 0.0670\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0805 - msle: 0.0805 - val_loss: 0.0667 - val_msle: 0.0667\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0801 - msle: 0.0801 - val_loss: 0.0664 - val_msle: 0.0664\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0798 - msle: 0.0798 - val_loss: 0.0661 - val_msle: 0.0661\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0794 - msle: 0.0794 - val_loss: 0.0658 - val_msle: 0.0658\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0791 - msle: 0.0791 - val_loss: 0.0655 - val_msle: 0.0655\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0787 - msle: 0.0787 - val_loss: 0.0651 - val_msle: 0.0651\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0784 - msle: 0.0784 - val_loss: 0.0648 - val_msle: 0.0648\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0780 - msle: 0.0780 - val_loss: 0.0645 - val_msle: 0.0645\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0776 - msle: 0.0776 - val_loss: 0.0642 - val_msle: 0.0642\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0773 - msle: 0.0773 - val_loss: 0.0639 - val_msle: 0.0639\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0769 - msle: 0.0769 - val_loss: 0.0636 - val_msle: 0.0636\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0766 - msle: 0.0766 - val_loss: 0.0632 - val_msle: 0.0632\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0762 - msle: 0.0762 - val_loss: 0.0629 - val_msle: 0.0629\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0758 - msle: 0.0758 - val_loss: 0.0626 - val_msle: 0.0626\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0755 - msle: 0.0755 - val_loss: 0.0623 - val_msle: 0.0623\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0751 - msle: 0.0751 - val_loss: 0.0619 - val_msle: 0.0619\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0747 - msle: 0.0747 - val_loss: 0.0616 - val_msle: 0.0616\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0743 - msle: 0.0743 - val_loss: 0.0613 - val_msle: 0.0613\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0740 - msle: 0.0740 - val_loss: 0.0610 - val_msle: 0.0610\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0736 - msle: 0.0736 - val_loss: 0.0606 - val_msle: 0.0606\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0732 - msle: 0.0732 - val_loss: 0.0603 - val_msle: 0.0603\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0728 - msle: 0.0728 - val_loss: 0.0600 - val_msle: 0.0600\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0725 - msle: 0.0725 - val_loss: 0.0596 - val_msle: 0.0596\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0721 - msle: 0.0721 - val_loss: 0.0593 - val_msle: 0.0593\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0717 - msle: 0.0717 - val_loss: 0.0590 - val_msle: 0.0590\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0713 - msle: 0.0713 - val_loss: 0.0586 - val_msle: 0.0586\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0709 - msle: 0.0709 - val_loss: 0.0583 - val_msle: 0.0583\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0705 - msle: 0.0705 - val_loss: 0.0579 - val_msle: 0.0579\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0701 - msle: 0.0701 - val_loss: 0.0576 - val_msle: 0.0576\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0697 - msle: 0.0697 - val_loss: 0.0573 - val_msle: 0.0573\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0693 - msle: 0.0693 - val_loss: 0.0569 - val_msle: 0.0569\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0690 - msle: 0.0690 - val_loss: 0.0566 - val_msle: 0.0566\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0686 - msle: 0.0686 - val_loss: 0.0562 - val_msle: 0.0562\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0682 - msle: 0.0682 - val_loss: 0.0559 - val_msle: 0.0559\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0678 - msle: 0.0678 - val_loss: 0.0556 - val_msle: 0.0556\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0674 - msle: 0.0674 - val_loss: 0.0552 - val_msle: 0.0552\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0670 - msle: 0.0670 - val_loss: 0.0549 - val_msle: 0.0549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0666 - msle: 0.0666 - val_loss: 0.0545 - val_msle: 0.0545\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0662 - msle: 0.0662 - val_loss: 0.0542 - val_msle: 0.0542\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0658 - msle: 0.0658 - val_loss: 0.0539 - val_msle: 0.0539\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0654 - msle: 0.0654 - val_loss: 0.0535 - val_msle: 0.0535\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0650 - msle: 0.0650 - val_loss: 0.0532 - val_msle: 0.0532\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0646 - msle: 0.0646 - val_loss: 0.0528 - val_msle: 0.0528\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0642 - msle: 0.0642 - val_loss: 0.0525 - val_msle: 0.0525\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0638 - msle: 0.0638 - val_loss: 0.0522 - val_msle: 0.0522\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0634 - msle: 0.0634 - val_loss: 0.0518 - val_msle: 0.0518\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0630 - msle: 0.0630 - val_loss: 0.0515 - val_msle: 0.0515\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0626 - msle: 0.0626 - val_loss: 0.0511 - val_msle: 0.0511\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0622 - msle: 0.0622 - val_loss: 0.0508 - val_msle: 0.0508\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0618 - msle: 0.0618 - val_loss: 0.0505 - val_msle: 0.0505\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0614 - msle: 0.0614 - val_loss: 0.0501 - val_msle: 0.0501\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0610 - msle: 0.0610 - val_loss: 0.0498 - val_msle: 0.0498\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0606 - msle: 0.0606 - val_loss: 0.0495 - val_msle: 0.0495\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0602 - msle: 0.0602 - val_loss: 0.0491 - val_msle: 0.0491\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0598 - msle: 0.0598 - val_loss: 0.0488 - val_msle: 0.0488\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0594 - msle: 0.0594 - val_loss: 0.0485 - val_msle: 0.0485\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0590 - msle: 0.0590 - val_loss: 0.0481 - val_msle: 0.0481\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0586 - msle: 0.0586 - val_loss: 0.0478 - val_msle: 0.0478\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0583 - msle: 0.0583 - val_loss: 0.0475 - val_msle: 0.0475\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0579 - msle: 0.0579 - val_loss: 0.0472 - val_msle: 0.0472\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0575 - msle: 0.0575 - val_loss: 0.0468 - val_msle: 0.0468\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0571 - msle: 0.0571 - val_loss: 0.0465 - val_msle: 0.0465\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0567 - msle: 0.0567 - val_loss: 0.0462 - val_msle: 0.0462\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0563 - msle: 0.0563 - val_loss: 0.0459 - val_msle: 0.0459\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0559 - msle: 0.0559 - val_loss: 0.0456 - val_msle: 0.0456\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0556 - msle: 0.0556 - val_loss: 0.0453 - val_msle: 0.0453\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0552 - msle: 0.0552 - val_loss: 0.0450 - val_msle: 0.0450\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0548 - msle: 0.0548 - val_loss: 0.0447 - val_msle: 0.0447\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0544 - msle: 0.0544 - val_loss: 0.0444 - val_msle: 0.0444\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0540 - msle: 0.0540 - val_loss: 0.0441 - val_msle: 0.0441\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0537 - msle: 0.0537 - val_loss: 0.0438 - val_msle: 0.0438\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0533 - msle: 0.0533 - val_loss: 0.0435 - val_msle: 0.0435\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0529 - msle: 0.0529 - val_loss: 0.0432 - val_msle: 0.0432\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0526 - msle: 0.0526 - val_loss: 0.0429 - val_msle: 0.0429\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0522 - msle: 0.0522 - val_loss: 0.0426 - val_msle: 0.0426\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0519 - msle: 0.0519 - val_loss: 0.0423 - val_msle: 0.0423\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0515 - msle: 0.0515 - val_loss: 0.0420 - val_msle: 0.0420\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0512 - msle: 0.0512 - val_loss: 0.0418 - val_msle: 0.0418\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0508 - msle: 0.0508 - val_loss: 0.0415 - val_msle: 0.0415\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0504 - msle: 0.0504 - val_loss: 0.0412 - val_msle: 0.0412\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0501 - msle: 0.0501 - val_loss: 0.0409 - val_msle: 0.0409\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0498 - msle: 0.0498 - val_loss: 0.0407 - val_msle: 0.0407\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0494 - msle: 0.0494 - val_loss: 0.0404 - val_msle: 0.0404\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0491 - msle: 0.0491 - val_loss: 0.0402 - val_msle: 0.0402\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0487 - msle: 0.0487 - val_loss: 0.0399 - val_msle: 0.0399\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0484 - msle: 0.0484 - val_loss: 0.0397 - val_msle: 0.0397\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0481 - msle: 0.0481 - val_loss: 0.0394 - val_msle: 0.0394\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0478 - msle: 0.0478 - val_loss: 0.0392 - val_msle: 0.0392\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0474 - msle: 0.0474 - val_loss: 0.0389 - val_msle: 0.0389\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0471 - msle: 0.0471 - val_loss: 0.0387 - val_msle: 0.0387\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0468 - msle: 0.0468 - val_loss: 0.0384 - val_msle: 0.0384\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0465 - msle: 0.0465 - val_loss: 0.0382 - val_msle: 0.0382\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0462 - msle: 0.0462 - val_loss: 0.0380 - val_msle: 0.0380\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0459 - msle: 0.0459 - val_loss: 0.0378 - val_msle: 0.0378\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0456 - msle: 0.0456 - val_loss: 0.0376 - val_msle: 0.0376\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0453 - msle: 0.0453 - val_loss: 0.0374 - val_msle: 0.0374\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0450 - msle: 0.0450 - val_loss: 0.0372 - val_msle: 0.0372\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0447 - msle: 0.0447 - val_loss: 0.0369 - val_msle: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0444 - msle: 0.0444 - val_loss: 0.0367 - val_msle: 0.0367\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0441 - msle: 0.0441 - val_loss: 0.0365 - val_msle: 0.0365\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0438 - msle: 0.0438 - val_loss: 0.0364 - val_msle: 0.0364\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0436 - msle: 0.0436 - val_loss: 0.0362 - val_msle: 0.0362\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0433 - msle: 0.0433 - val_loss: 0.0360 - val_msle: 0.0360\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0430 - msle: 0.0430 - val_loss: 0.0358 - val_msle: 0.0358\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0428 - msle: 0.0428 - val_loss: 0.0356 - val_msle: 0.0356\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0425 - msle: 0.0425 - val_loss: 0.0354 - val_msle: 0.0354\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0423 - msle: 0.0423 - val_loss: 0.0353 - val_msle: 0.0353\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0420 - msle: 0.0420 - val_loss: 0.0351 - val_msle: 0.0351\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0418 - msle: 0.0418 - val_loss: 0.0349 - val_msle: 0.0349\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0416 - msle: 0.0416 - val_loss: 0.0348 - val_msle: 0.0348\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0413 - msle: 0.0413 - val_loss: 0.0346 - val_msle: 0.0346\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0411 - msle: 0.0411 - val_loss: 0.0344 - val_msle: 0.0344\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0408 - msle: 0.0408 - val_loss: 0.0343 - val_msle: 0.0343\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0406 - msle: 0.0406 - val_loss: 0.0341 - val_msle: 0.0341\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0404 - msle: 0.0404 - val_loss: 0.0340 - val_msle: 0.0340\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0402 - msle: 0.0402 - val_loss: 0.0338 - val_msle: 0.0338\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0400 - msle: 0.0400 - val_loss: 0.0337 - val_msle: 0.0337\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0397 - msle: 0.0397 - val_loss: 0.0335 - val_msle: 0.0335\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 790       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 833\n",
      "Trainable params: 833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ We coded a `plot_history` function that you can use to detect overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(np.sqrt(history.history['loss']))\n",
    "    plt.plot(np.sqrt(history.history['val_loss']))\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('RMSLE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed = preproc.transform(X_test)\n",
    "y_pred = model.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df[\"Id\"] = X_test[\"Id\"]\n",
    "results_df[\"SalePrice\"] = y_pred\n",
    "results_df.set_index(\"Id\", inplace=True)\n",
    "results_df.to_csv(\"data/submission_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Challenging yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î **Questions to challenge yourself:**\n",
    "- Are you satisfied with your score?\n",
    "- Before publishing it, ask yourself whether you could really trust it or not?\n",
    "- Have you cross-validated your neural network? \n",
    "    - Feel free to cross-validate it manually with a *for loop* in Python to make sure that your results are robust against the randomness of a _train-val split_ before before submitting to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function `evaluate_model` following the framework below üëá then use a for loop with `KFold` to manually cross validate your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, train_index, val_index):\n",
    "    \n",
    "    # Slicing the training set and the validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y,  test_size = 0.30)\n",
    "    \n",
    "    # Preprocessing \n",
    "    X_train = preproc.transform(X_train)\n",
    "    X_val = preproc.transform(X_val)\n",
    "    \n",
    "    # Training the model on the preprocessed training dataset\n",
    "    model.fit(X_train, y_train, epochs=500)\n",
    "    \n",
    "    # Evaluating the model on the preprocessed validation dataset\n",
    "    model.evaluate(X_val, y_val)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "                'rmsle_final_epoch': [\"rmsle\"],\n",
    "                'rmsle_min': [\"min_rmsle\"]\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) (Bonus) Using all your CPU cores to run Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• **BONUS** üî• **Multiprocessing computing using [dask](https://docs.dask.org/en/latest/delayed.html)** and **all your CPU cores**:\n",
    "\n",
    "_(to mimic SkLearn's `n_jobs=-1`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from dask import delayed\n",
    "\n",
    "# cv = 5\n",
    "# kf = KFold(n_splits = cv, shuffle = True)\n",
    "# f = delayed(evaluate_model)\n",
    "\n",
    "# results = delayed([f(X, y, train_index, val_index) for (train_index, val_index) in kf.split(X)\n",
    "#                   ]).compute(\n",
    "#                       scheduler='processes', num_workers=8)\n",
    "\n",
    "# pd.concat(results, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (2.4) (Bonus) Multiprocessing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "**multiprocessing with default Python library**\n",
    "\n",
    "References :\n",
    "* [Yitong Ren - Speeding Up and Perfecting Your Work Using Parallel Computing](https://towardsdatascience.com/speeding-up-and-perfecting-your-work-using-parallel-computing-8bc2f0c073f8)\n",
    "* [Johaupt Github - Parallel Processing for Cross Validation - BROKEN LINK](https://johaupt.github.io/python/parallel%20processing/cross-validation/multiprocessing_cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_result\u001b[39m(x):\n\u001b[1;32m      7\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, val_index \u001b[38;5;129;01min\u001b[39;00m \u001b[43mkf\u001b[49m\u001b[38;5;241m.\u001b[39msplit(X):\n\u001b[1;32m     10\u001b[0m     pool\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[1;32m     11\u001b[0m         evaluate_model,\n\u001b[1;32m     12\u001b[0m         args\u001b[38;5;241m=\u001b[39m(X, y, train_index, val_index),\n\u001b[1;32m     13\u001b[0m         callback \u001b[38;5;241m=\u001b[39m log_result)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Close the pool for new tasks\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kf' is not defined"
     ]
    }
   ],
   "source": [
    "# This code will fail try to debug it yourself if you cannot checkout the hints below\n",
    "import multiprocessing as mp\n",
    "pool = mp.Pool(processes=2) #mp.cpu_count()-1)\n",
    "\n",
    "results = []\n",
    "def log_result(x):\n",
    "    results.append(x)\n",
    "    \n",
    "for train_index, val_index in kf.split(X):\n",
    "    pool.apply_async(\n",
    "        evaluate_model,\n",
    "        args=(X, y, train_index, val_index),\n",
    "        callback = log_result)\n",
    "\n",
    "# Close the pool for new tasks\n",
    "pool.close()\n",
    "\n",
    "# Wait for all tasks to complete at this point\n",
    "pool.join()\n",
    "\n",
    "result = pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary markdown='span'>Hints</summary>\n",
    "\n",
    "This is a limitation of multiprocessing in ipython enviroments this code would work fine in .py file.\n",
    "The key error is `AttributeError: Can't get attribute 'evaluate_model' on <module 'main' (built-in)>`\n",
    "\n",
    "Checkout this stackoverflow for a workaround https://stackoverflow.com/questions/41385708/multiprocessing-example-giving-attributeerror !\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) üèÖFINAL SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü¶Ñ Predict the ***prices of the houses in your test set*** and submit your results to Kaggle! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")\n",
    "# X_test_preproc = preproc.transform(X_test)\n",
    "# ALREADY DONE ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Save your predictions in a Dataframe called `results` with the format required by Kaggle so that when you export it to a `.csv`, Kaggle can read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì§  Export your results using Kaggle's submission format and submit it online!\n",
    "\n",
    "_(Uncomment the last cell of this notebook)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.to_csv(\"submission_final.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "üèÅ Congratulations!\n",
    "\n",
    "üíæ Don't forget to `git add/commit/push` your notebook...\n",
    "\n",
    "üöÄ ... it's time for the Recap!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
